= Goal Dependency Thesis Project

== Abstract

In this project, the use of deep neural networks for the process of selecting actions to execute within an environment to achieve a goal is explored. Scenarios like this are common in crafting based games such as Terraria or Minecraft. Goals in these environments have recursive sub-goal dependencies which form a dependency tree. The agent operating within these environments have access to low amounts of data about the environment before interacting with it, so it is crucial that this agent is able to effectively utilize its tree of dependencies and its environmental surroundings to make judgements about which sub-goals are most efficient to pursue at any point in time. A successful agent minimizes cost when completing a given goal. A deep neural network in combination with Q-learning techniques was employed to act as the agent in this environment. This agent consistently performed better than agents using alternate models (models that used dependency tree heuristics or human-like approaches to make sub-goal oriented choices), with an average performance advantage of 22.56% over the best alternate agent. This shows that machine learning techniques can be effectively employed to make goal-oriented choices within an environment with recursive sub-goal dependencies and low amounts of pre-known information.

== Requirements

- Python 3
    If you plan on using Tensorflow with GPU support, this must be Python 3.5

- Graphviz (Optional)
    Graphviz has two components. There's a pip package that's noted below,
    but also has an https://www.graphviz.org/Download.php[executable] that you must have in your path in order for some components of this project to work.

- Tensorflow (optionally with GPU support)

=== pip Requirements

Install pip requirements with

`$make init`

== Usage

The project has a makefile that can be used for convenience rather than calling the scripts directly.
At this point in the project, none of the scripts are set up to handle CLI calls, so you'll have to edit parts of the scripts (namely `src/main.py`) to have the functionality you want. Running

`$make`

will run `src/main.py`.

=== Editing Scripts for Different Functionality

* change the value of `simname` at the top of `main.py` to change between simulation configs
** Simulation configs are located in `json/simulation_configs`. Duplicate and edit one of the existing ones to specifiy alternate worlds/goals.
* change the value of RENDER_TREE at the top of `main.py` to enable or disable rendering of the dependency tree
* change the last line of `main.py` to switch between training/searching for a model and benchmarking a specific model
** to specify the specific model to benchmark, use the filepath (excluding the extension) of a model in `trainedModels` (including `trainedModels` in the filepath)


== File overviews

=== `src`

* action.py: Contains the Action class.
* actionFactory.py: Contains the ActionFactory class.
* actionTarget.py: Contains the ActionTarget class.
* dependencyTree.py: Is used to construct a dependency tree given an ActionFactory and a goal PS.
* gameController.py: Contains the GameController class. GameController executes actions on the current GameState.
* gameState.py: Contains the GameState class. GameState contains PlayerMemory, an InventoryManager, and a GameWorld2d.
* gameWorld2d.py: Contains the GameWorld2d class. GameWorld2d is the world model for the simulation. It is initialized with an image which it parses to determine the world environment. GameWorld2d contains methods relevant to movement such as pathfinding algorithms, as well as world visualization and analysis methods.
* inventoryManager.py: Contains the InventoryManager class. InventoryManager is the inventory model for the simulation.
* main.py: The system’s main file. Is responsible for building and training the goal selection DNN, as well as benchmarking and analyzing the DNN.
* playerMemory.py: Contains the PlayerMemory class. PlayerMemory contains execution overhead such as the agent’s currently selected AT as well as metrics and information about the current simulation so far.
* playerState.py: Contains the PlayerState class.
* playerStateSolution.py: Contains the PlayerStateSolution class.
* playerStateTarget.py: Contains the PlayerStateTarget class.
* test.py: Contains tests (mostly unit tests) for PlayerState/ PlayerStateSolution/ PlayerStateTarget/ Dependency Tree functionality.
* util.py: Contains convenience utility methods.

=== `json`

* benchmark_sets: contains set of positions used to benchmark agents on given worlds
* simulation_configs: contains set of config files that lay out worlds and goals for different simulations
* simulation_stats: contains simulation statistics for different simulation runs
* world_configs: contains precalculated static costs for specific actions for given worlds.
* actionMemory.json: contains every known action with the required and resultant PlayerState
* craftingIndex.json: contains where and what is placed in a crafting bench during crafting. Contains some extra information which at one point pertained to minecraft but is still valueable in BlockLand.
* environmentIndex.json: contains what tool to use and how long to take to harvest a block (used by gameController.py)
* inventoryItem.json: contains information about tools including tool level, stack size, and tool type

=== `resources`

* 2d: contains 2d world files that are parsed to create a world at the beginning of a simulation

=== `simulation`

* 2Dpath: contains snapshots of worlds at points where actions are completed during simulation. Only populated when world rendering is enabled in `src/main.py`
* trees: contians shapshots of the dependency tree at points where actions are completed during simulation. Only populated when tree rendering is enabled in `src/main.py`
* [selection_method]_animation.gif: rendering of a simulation using a specified selection method. Only used for demonstration purposes.

=== `trainedModels`

* [simulation_config_name]_[performance_improvement].meta: a trained tensorflow model for [simulation_config_name] (found in `json/simulation_configs`) that exhibited an improvement of [performance_improvement] during training.

=== `uml`

* system_activity.jpg: an activity diagram demonstrating the general flow of a simulation
* system_class.jpg: a system-level class diagram
* uml_sem_2.mdj: a StarUML file containing the aformentioned UML diagrams.


== Recommended Code Improvements

Note: these improvements are separate from the improvements outlined in the thesis document.

* `src/main.c`
** Stop training models once they have a specific advantage over other agents (based on initial benchmarking) rather than having a specific level of improvement over its previous self (based on initial benchmarking)
** ActionTargetSelectors
*** Refactor switching costs to factor in the sum of the switching costs for an entire chain of sequentially dependent actions if there is such a chain of sequentially dependent actions


* `src/gameWorld2d.py`
** Add option to randomly generate a world

* `src/dependencyTree.py`
** Show rewound/rolled back nodes on the rendered graphs (they need to be added back into levelIndex after being rewound since they're pruned from levelIndex when initially completed)






== Developer

Copyright 2017 Derek Koleber under MIT License
